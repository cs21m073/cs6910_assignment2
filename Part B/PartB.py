# -*- coding: utf-8 -*-
"""PartB_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MWc74gaYCpMX4DquIMhy6ufNdLF1CSgV
"""

import numpy as np 
import os
import tensorflow as tf
import matplotlib.image as mpimg
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow import keras
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt
import cv2
from keras.applications.inception_v3 import InceptionV3
from keras.applications.inception_resnet_v2 import InceptionResNetV2
#from keras.applications.resnet50 import ResNet50
from keras.applications.xception import Xception


##Creating the dataset from google drive
Path = '/content/drive/MyDrive/inaturalist_12K'

trainPath = os.path.join(Path, "train") #training data path
valPath = os.path.join(Path, "val") #validation data path

def createDataset(augmentData=False, preTrainedModel = 'InceptionV3'):
  imageSize = 299
  if preTrainedModel == 'InceptionV3':
    #default imageSize for inceptionv3 is 299
    imageSize = 299

  elif preTrainedModel == 'InceptionResNetV2':
    #default imageSize for inceptionv3 is 299
    imageSize = 299
    
  elif preTrainedModel == 'ResNet50':
    #default imageSize for inceptionv3 is 224
    imageSize = 224
    
  elif preTrainedModel == 'Xception':
    #default imageSize for inceptionv3 is 299
    imageSize = 299

  if augmentData == True:
    train_ = ImageDataGenerator(rescale=1./255, zoom_range=0.2, shear_range=0.2, rotation_range=90, horizontal_flip=True, validation_split=0.1)
  else:
    train_ = ImageDataGenerator(rescale=1./255, validation_split=0.1)
  
  val_ = ImageDataGenerator(rescale=1./255)

  trainData = train_.flow_from_directory(trainPath, target_size=(imageSize, imageSize), batch_size=128, subset="training", shuffle =True, seed = 123)
  testData = train_.flow_from_directory(trainPath, target_size=(imageSize, imageSize), batch_size=128, subset="validation", shuffle = True, seed = 123)
  valData = val_.flow_from_directory(valPath, target_size=(imageSize, imageSize), batch_size=128)

  return trainData, testData, valData

  

class NeuralNetwork:
  def __init__(self):
    pass

  def modelCreation(self, denseSize=128, imageSize=299, dropout=0.4, batchNorm=False, preTrainedModel='InceptionV3'):
    if preTrainedModel == 'InceptionV3':
      #default imageSize for inceptionv3 is 299
      imageSize = 299
      model = InceptionV3(include_top=False, input_shape=(imageSize, imageSize,3), weights='imagenet')

    elif preTrainedModel == 'InceptionResNetV2':
      #default imageSize for inceptionv3 is 299
      imageSize = 299
      model = InceptionResNetV2(include_top=False, input_shape=(imageSize, imageSize,3), weights='imagenet')
    
    elif preTrainedModel == 'ResNet50':
      #default imageSize for inceptionv3 is 224
      imageSize = 224
      model = tf.keras.applications.resnet50.ResNet50(include_top=False, input_shape=(imageSize, imageSize,3), weights='imagenet')
    
    elif preTrainedModel == 'Xception':
      #default imageSize for inceptionv3 is 299
      imageSize = 299
      model = Xception(include_top=False, input_shape=(imageSize, imageSize,3), weights='imagenet')  


    for layers in model.layers:
      layers.trainable = False

    model = keras.Sequential([
        tf.keras.Input(shape=(imageSize, imageSize,3,)), model, Flatten(), Dense(denseSize,activation='relu'),])
    
    if batchNorm:
      model.add(BatchNormalization())
    model.add(Dropout(dropout))
    model.add(Dense(denseSize, activation='relu'))
    model.add(Dropout(dropout))
    model.add(Dense(10 ,activation='softmax'))

    return model


    #Training the model
  def trainModel(self, denseSize, dropout, batchNorm, preTrainModel, lr, epochs, augment_data):        
       
        trainData, testData, valData = createDataset(augment_data, preTrainModel)

        #structure of modelCreation(self, denseSize=128, imageSize=299, dropout=0.4, batchNorm=False, preTrainedModel='inceptionv3'):
        model = self.modelCreation(denseSize, imageSize=299, dropout=dropout, batchNorm=batchNorm, preTrainedModel=preTrainModel)

       # model.compile(optimizer=keras.optimizers.Adam(config.lr), loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
        #Training model and fine tuning
        tuningParameters = {
          "InceptionV3": 55,
          "InceptionResNetV2": 55,
          "ResNet50": 50,
          "Xception": 50
        }

        model.trainanle = True
        fineTuneTo = len(model.layers) - tuningParameters[preTrainModel]

        for layer in model.layers[:fineTuneTo]:
          layer.trainable =  False

        model.compile(optimizer=keras.optimizers.Adam(lr), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])
        model.fit(trainData, epochs=epochs, validation_data=testData)
        print("Training and Tuning Completed")

from sys import argv
if __name__ ==  "__main__":
  denseSize = int(argv[1])
  dropout = float(argv[2])
  if argv[3] == "True":
    batchNorm = True
  else:
    batchNorm = False
  
  preTrainModel = argv[4]
  lr = float(argv[5])
  epochs = int(argv[6])
  if argv[7] == "True":
  	augment_data = True
  else:
  	augment_data = False

  obj = NeuralNetwork()
  obj.trainModel(denseSize, dropout, batchNorm, preTrainModel, lr, epochs, augment_data)
